{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d11db97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:35: SyntaxWarning: \"\\E\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\E\"? A raw string is also an option.\n",
      "<>:35: SyntaxWarning: \"\\E\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\E\"? A raw string is also an option.\n",
      "C:\\Users\\samee\\AppData\\Local\\Temp\\ipykernel_20372\\623180346.py:35: SyntaxWarning: \"\\E\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\E\"? A raw string is also an option.\n",
      "  df = pd.read_csv('D:\\EDUNet\\p1-1.csv', usecols=features_to_load)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import cycle\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "print(\"Loading data...\")\n",
    "\n",
    "features_to_load = [\n",
    "    'common_name', \n",
    "    'ward_name', \n",
    "    'ownership', \n",
    "    'girth_cm', \n",
    "    'height_m', \n",
    "    'canopy_dia_m', \n",
    "    'condition'\n",
    "]\n",
    "\n",
    "numerical_features = ['girth_cm', 'height_m', 'canopy_dia_m']\n",
    "categorical_features = ['common_name', 'ward_name', 'ownership']\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('D:\\EDUNet\\p1-1.csv', usecols=features_to_load)\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: tree_data.csv not found. Make sure it's in the same folder.\")\n",
    "    exit()\n",
    "except ValueError as e:\n",
    "    print(f\"ERROR: A required column is missing from tree_data.csv. {e}\")\n",
    "    exit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ff125c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Validation Report ---\n",
      "1. Checking Data Types (Original):\n",
      "girth_cm        float64\n",
      "height_m        float64\n",
      "canopy_dia_m    float64\n",
      "condition        object\n",
      "ownership        object\n",
      "ward_name       float64\n",
      "common_name      object\n",
      "dtype: object\n",
      "\n",
      "Data types after conversion:\n",
      "girth_cm        float64\n",
      "height_m        float64\n",
      "canopy_dia_m    float64\n",
      "condition        object\n",
      "ownership        object\n",
      "ward_name        object\n",
      "common_name      object\n",
      "dtype: object\n",
      "\n",
      "2. Checking for Null Values (Before Cleaning):\n",
      "girth_cm        1\n",
      "height_m        1\n",
      "canopy_dia_m    1\n",
      "condition       1\n",
      "ownership       0\n",
      "ward_name       0\n",
      "common_name     0\n",
      "dtype: int64\n",
      "-------------------------------\n",
      "\n",
      "Cleaning data...\n",
      "Initial row count: 1000001\n",
      "Row count after dropping missing labels: 1000000\n",
      "Creating train-test split (80/20)...\n",
      "Training samples: 800000, Testing samples: 200000\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Data Validation & Pre-Cleaning ---\n",
    "print(\"\\n--- Data Validation Report ---\")\n",
    "\n",
    "print(\"1. Checking Data Types (Original):\")\n",
    "print(df.dtypes)\n",
    "\n",
    "for col in numerical_features:\n",
    "    if df[col].dtype == 'object':\n",
    "        print(f\"Warning: Column '{col}' is 'object', converting to numeric.\")\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "for col in categorical_features:\n",
    "    df[col] = df[col].astype(str)\n",
    "\n",
    "print(\"\\nData types after conversion:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n2. Checking for Null Values (Before Cleaning):\")\n",
    "print(df.isnull().sum())\n",
    "print(\"-------------------------------\\n\")\n",
    "\n",
    "print(\"Cleaning data...\")\n",
    "print(f\"Initial row count: {len(df)}\")\n",
    "\n",
    "df = df.dropna(subset=['condition'])\n",
    "df = df.dropna(subset=['common_name'])\n",
    "df[categorical_features] = df[categorical_features].replace('nan', np.nan)\n",
    "\n",
    "print(f\"Row count after dropping missing labels: {len(df)}\")\n",
    "\n",
    "if len(df) == 0:\n",
    "    print(\"ERROR: No data left after cleaning. Please check your tree_data.csv for valid 'condition' and 'common_name' fields.\")\n",
    "    exit()\n",
    "\n",
    "X = df.drop('condition', axis=1)\n",
    "y = df['condition']\n",
    "\n",
    "CLASS_NAMES = np.sort(y.unique())\n",
    "\n",
    "print(\"Creating train-test split (80/20)...\")\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2,\n",
    "        random_state=42, \n",
    "        stratify=y\n",
    "    )\n",
    "except ValueError:\n",
    "    print(\"Warning: Not enough samples for a stratified split. Using a non-stratified split.\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "print(f\"Training samples: {len(X_train)}, Testing samples: {len(X_test)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abe3e60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining preprocessing pipelines...\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Define Preprocessing Pipelines ---\n",
    "print(\"Defining preprocessing pipelines...\")\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6aebb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Create the Full Preprocessor ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80d5660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining models to compare...\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Define Models to Compare ---\n",
    "print(\"Defining models to compare...\")\n",
    "\n",
    "models_to_compare = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42, max_depth=20),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "model_results = {}\n",
    "best_model_pipeline = None \n",
    "best_model_accuracy = 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9782a942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Comparison (using 80/20 split) ---\n",
      "Testing model: Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\EDUNet\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Test Accuracy = 91.72%\n",
      "Testing model: Decision Tree...\n",
      "Decision Tree: Test Accuracy = 93.64%\n",
      "Testing model: Random Forest...\n",
      "Random Forest: Test Accuracy = 94.08%\n",
      "Testing model: Gradient Boosting...\n",
      "Gradient Boosting: Test Accuracy = 93.84%\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Compare Models using Train-Test Split ---\n",
    "print(\"\\n--- Model Comparison (using 80/20 split) ---\")\n",
    "    \n",
    "for name, model in models_to_compare.items():\n",
    "    print(f\"Testing model: {name}...\")\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        mean_accuracy = accuracy_score(y_test, y_pred)\n",
    "        model_results[name] = mean_accuracy\n",
    "        \n",
    "        print(f\"{name}: Test Accuracy = {mean_accuracy*100:.2f}%\")\n",
    "        \n",
    "        if mean_accuracy > best_model_accuracy:\n",
    "            best_model_accuracy = mean_accuracy\n",
    "            best_model_pipeline = pipeline \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Could not evaluate model {name}. Error: {e}\")\n",
    "        model_results[name] = 0.0\n",
    "\n",
    "print(\"------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70ee62be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Detailed Report for Best Model: Random Forest ---\n",
      "Test Accuracy: 94.08%\n",
      "\n",
      "1. Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Average       0.65      0.46      0.54     13223\n",
      "        Dead       0.84      0.83      0.83      4285\n",
      "     Healthy       0.96      0.98      0.97    181771\n",
      "        Poor       0.19      0.03      0.06       721\n",
      "\n",
      "    accuracy                           0.94    200000\n",
      "   macro avg       0.66      0.58      0.60    200000\n",
      "weighted avg       0.93      0.94      0.94    200000\n",
      "\n",
      "2. Generating Confusion Matrix (saving to confusion_matrix.png)...\n",
      "Saved confusion_matrix.png\n",
      "3. Generating ROC/AUC Curves (saving to roc_auc_curves.png)...\n",
      "Saved roc_auc_curves.png\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Find and Evaluate the Best Model ---\n",
    "best_model_name = max(model_results, key=model_results.get)\n",
    "\n",
    "if best_model_pipeline is None:\n",
    "     print(\"ERROR: All models failed to train. Exiting.\")\n",
    "     exit()\n",
    "\n",
    "print(f\"\\n--- Detailed Report for Best Model: {best_model_name} ---\")\n",
    "print(f\"Test Accuracy: {best_model_accuracy*100:.2f}%\")\n",
    "\n",
    "y_pred = best_model_pipeline.predict(X_test)\n",
    "y_prob = best_model_pipeline.predict_proba(X_test)\n",
    "\n",
    "print(\"\\n1. Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, labels=CLASS_NAMES))\n",
    "\n",
    "print(\"2. Generating Confusion Matrix (saving to confusion_matrix.png)...\")\n",
    "try:\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=CLASS_NAMES)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "    plt.title(f'Confusion Matrix for {best_model_name}')\n",
    "    plt.ylabel('Actual Condition')\n",
    "    plt.xlabel('Predicted Condition')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "    print(\"Saved confusion_matrix.png\")\n",
    "except Exception as e:\n",
    "    print(f\"Error generating confusion matrix: {e}\")\n",
    "\n",
    "print(\"3. Generating ROC/AUC Curves (saving to roc_auc_curves.png)...\")\n",
    "try:\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(CLASS_NAMES)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    n_classes = len(CLASS_NAMES)\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_prob[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_binarized.ravel(), y_prob.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label=f'Micro-average ROC curve (area = {roc_auc[\"micro\"]:0.2f})',\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "    # Plot ROC for each class\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                 label=f'ROC curve of class {CLASS_NAMES[i]} (area = {roc_auc[i]:0.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Multi-Class ROC/AUC Curves for {best_model_name}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('roc_auc_curves.png')\n",
    "    plt.close()\n",
    "    print(\"Saved roc_auc_curves.png\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error generating ROC/AUC curves: {e}\")\n",
    "    if (y_prob.shape[1] != len(CLASS_NAMES)):\n",
    "        print(f\"Debug Info: y_prob shape {y_prob.shape[1]} != n_classes {len(CLASS_NAMES)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05b66cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the final best model (Random Forest) on ALL data (100%)...\n",
      "Final model training complete.\n",
      "Best model pipeline (Random Forest) saved to tree_model_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "# --- 8. Train and Save the FINAL Model ---\n",
    "print(f\"\\nTraining the final best model ({best_model_name}) on ALL data (100%)...\")\n",
    "\n",
    "final_classifier = models_to_compare[best_model_name]\n",
    "\n",
    "final_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', final_classifier)\n",
    "])\n",
    "\n",
    "final_pipeline.fit(X, y)\n",
    "print(\"Final model training complete.\")\n",
    "\n",
    "pipeline_filename = 'tree_model_pipeline.pkl'\n",
    "with open(pipeline_filename, 'wb') as file:\n",
    "    pickle.dump(final_pipeline, file)\n",
    "\n",
    "print(f\"Best model pipeline ({best_model_name}) saved to {pipeline_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
